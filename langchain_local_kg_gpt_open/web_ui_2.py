import os
import gradio as gr
from collections import defaultdict
from application.qa_bot import QABot,QABotConfig


# ç”¨æˆ·å†å²æ¶ˆæ¯è®°å½•
user_chat_history = defaultdict(list)
# äº§å“åç§°åˆ°idçš„æ˜ å°„
name_id_map = {"æ€åŠ å›¾å¤å¤å‡‰é‹":"145","ONGé€æ°”è·‘é‹":"196"}
#QA boot
config = QABotConfig(embedding_model_name="./embed_model/shibing624-text2vec-base-chinese",
                     docs_path="./test_data/shoes_data.tsv",
                     vector_store_path = "./test_data",
                     history_len=10)
bot = QABot(config)


def predict(query,
            large_language_model,
            top_k,
            goods_name,
            history=None):
    if history == None:
        history = []
    goods_id = name_id_map[goods_name]
    result,search = bot.get_knowledge_based_answer(query,
                                                    large_language_model,
                                                    goods_id,
                                                    top_k=top_k,
                                                    chat_history=user_chat_history[goods_id])

    if result != "æœåŠ¡è°ƒç”¨å¤±è´¥":
        user_chat_history[goods_id].append(["user",query])
        user_chat_history[goods_id].append(["assistant",result])
    history.append([query, result])
    return '', history, history, search


def clear_session(request: gr.Request):
    return '', None


init_message = "æˆ‘æ˜¯ShoesGPTï¼Œä½ é«˜å…´ä¸ºä½ æœåŠ¡ã€‚"
block_css = """
.importantButton {
    background: linear-gradient(45deg, #7e0570,#5d1c99, #6e00ff) !important;
    border: none !important;
}
.importantButton:hover {
    background: linear-gradient(45deg, #ff00e0,#8500ff, #6e00ff) !important;
    border: none !important;
}
"""
default_theme_args = dict(
    font=["Source Sans Pro", 'ui-sans-serif', 'system-ui', 'sans-serif'],
    font_mono=['IBM Plex Mono', 'ui-monospace', 'Consolas', 'monospace'],
)

with gr.Blocks(css=block_css, theme=gr.themes.Default(**default_theme_args)) as demo:
    gr.Markdown("""<h1><center>ShoesGPT</center></h1><center><font size=3></center></font>""")
    state = gr.State()

    with gr.Row():
        with gr.Column(scale=1):
            goods_name = gr.Dropdown(
                [
                    "æ€åŠ å›¾å¤å¤å‡‰é‹",
                    "ONGé€æ°”è·‘é‹",
                ],
                label="å•†å“åˆ—è¡¨",
                value="æ€åŠ å›¾å¤å¤å‡‰é‹")

            embedding_model = gr.Dropdown(
                [
                "shibing624/text2vec-base-chinese"
                ],
                label="å‘é‡åŒ–æ¨¡å‹",
                value="shibing624/text2vec-base-chinese")

            large_language_model = gr.Dropdown(
                [
                    "ChatGPT",
                    "ChatGLM-6B",
                    "ChatGLM-6B-SFT",
                ],
                label="large language model",
                value="ChatGPT")

            top_k = gr.Slider(3,
                              10,
                              value=3,
                              step=1,
                              label="æ£€ç´¢top-kæ–‡æ¡£",
                              interactive=True)

        with gr.Column(scale=4):
            with gr.Row():
                chatbot = gr.Chatbot([[None, init_message]],label=" ").style(height=400)
            with gr.Row():
                message = gr.Textbox(label='è¯·è¾“å…¥é—®é¢˜')
            with gr.Row():
                clear_history = gr.Button("ğŸ§¹ æ¸…é™¤å†å²å¯¹è¯")
                send = gr.Button("ğŸš€ å‘é€")

        with gr.Column(scale=2):
            search = gr.Textbox(label='æœç´¢ç»“æœ')

        # ============= è§¦å‘åŠ¨ä½œ=============
        # å‘é€æŒ‰é’® æäº¤
        send.click(predict,
                   inputs=[
                       message,
                       large_language_model,
                       top_k,
                       goods_name
                   ],
                   outputs=[message, chatbot, state, search])
        # æ¸…ç©ºå†å²å¯¹è¯æŒ‰é’® æäº¤
        clear_history.click(fn=clear_session,
                            inputs=[],
                            outputs=[chatbot, state],
                            queue=False)
        # è¾“å…¥æ¡† å›è½¦
        message.submit(predict,
                       inputs=[
                           message,
                           large_language_model,
                           top_k,
                           goods_name,
                           state
                       ],
                       outputs=[message, chatbot, state, search])

demo.queue().launch(
    server_name='0.0.0.0',
    server_port=7860,
    share=False,
    show_error=True,
    debug=True,
    enable_queue=True,
    inbrowser=True
)
